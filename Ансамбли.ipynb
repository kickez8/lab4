{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085ec43-34bb-4afb-9515-517e0489db3e",
   "metadata": {},
   "source": [
    "## Ансамбли и полносвязные нейронные сети\n",
    "В этом ноутбуке вам нужно обучить модели на датасете классификации из предыдущего ноутбука и сравнить результаты. Вам будет предоставлен baseline, на основе которого вы будете доделывать предсказывающие модели. Оценка лабы будет зависеть от ROC-AUC на тестовых данных по следующим критериям:\n",
    "\\\n",
    "AUC - на тестовых данных\n",
    "- $AUC \\leq 0.76$ - 0 баллов\n",
    "- $0.76 < AUC \\leq 0.77$ - 2 балла\n",
    "- $0.77 < AUC \\leq 0.78$ - 4 балла\n",
    "- $0.78 < AUC \\leq 0.79$ - 6 баллов\n",
    "- $0.79 < AUC \\leq 0.80$ - 8 баллов\n",
    "- $AUC > 0.80$ - 10 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# БЛОК 1: ЗАГРУЗКА ДАННЫХ И ПЕРВИЧНЫЙ АНАЛИЗ\n",
    "print(\"=== ЭКСПЕРИМЕНТ 1: Базовые модели (Baseline) ===\")\n",
    "print(\"Что менял в параметрах: Все модели с параметрами по умолчанию\")\n",
    "print(\"Цель: установить baseline производительности\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "print(\"Первые 5 строк данных:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:].to_numpy()\n",
    "y = data.iloc[:, 0].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nРаспределение классов в тренировочной выборке:\")\n",
    "print(f\"Класс 0: {np.sum(y_train == 0)} samples\")\n",
    "print(f\"Класс 1: {np.sum(y_train == 1)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93737ec-e5eb-4d72-8beb-5dba4d4c581f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=2, edgecolor='k')\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf8d00-92a3-4b62-bca4-d854b72574d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# БЛОК 2: БАЗОВЫЕ МОДЕЛИ (BASELINE)\n",
    "print(\"\\n--- Обучение базовых моделей ---\")\n",
    "\n",
    "# Random Forest Baseline\n",
    "rf_model_baseline = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_baseline.fit(X_train, y_train)\n",
    "rf_pred_baseline = rf_model_baseline.predict(X_test)\n",
    "rf_roc_auc_baseline = roc_auc_score(y_test, rf_pred_baseline)\n",
    "\n",
    "print(f\"Random Forest Baseline - ROC AUC: {rf_roc_auc_baseline:.3f}\")\n",
    "\n",
    "# Gradient Boosting Baseline\n",
    "gb_model_baseline = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model_baseline.fit(X_train, y_train)\n",
    "gb_pred_baseline = gb_model_baseline.predict(X_test)\n",
    "gb_roc_auc_baseline = roc_auc_score(y_test, gb_pred_baseline)\n",
    "\n",
    "print(f\"Gradient Boosting Baseline - ROC AUC: {gb_roc_auc_baseline:.3f}\")\n",
    "\n",
    "# MLP Baseline\n",
    "mlp_model_baseline = MLPClassifier(hidden_layer_sizes=(30,), max_iter=500, random_state=42)\n",
    "mlp_model_baseline.fit(X_train, y_train)\n",
    "mlp_pred_baseline = mlp_model_baseline.predict(X_test)\n",
    "mlp_roc_auc_baseline = roc_auc_score(y_test, mlp_pred_baseline)\n",
    "\n",
    "print(f\"MLP Baseline - ROC AUC: {mlp_roc_auc_baseline:.3f}\")\n",
    "# БЛОК 3: ОПТИМИЗАЦИЯ RANDOM FOREST\n",
    "print(\"\\n=== ЭКСПЕРИМЕНТ 2: Оптимизация Random Forest ===\")\n",
    "print(\"Что менял в параметрах: GridSearchCV по n_estimators, max_depth, min_samples_split\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "print(\"Начинаем оптимизацию Random Forest...\")\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры Random Forest: {rf_grid.best_params_}\")\n",
    "\n",
    "rf_model_optimized = rf_grid.best_estimator_\n",
    "rf_pred_optimized = rf_model_optimized.predict(X_test)\n",
    "rf_roc_auc_optimized = roc_auc_score(y_test, rf_pred_optimized)\n",
    "\n",
    "print(f\"Random Forest Optimized - ROC AUC: {rf_roc_auc_optimized:.3f}\")\n",
    "print(f\"Улучшение: +{rf_roc_auc_optimized - rf_roc_auc_baseline:.3f}\")\n",
    "# БЛОК 4: ОПТИМИЗАЦИЯ GRADIENT BOOSTING\n",
    "print(\"\\n=== ЭКСПЕРИМЕНТ 3: Оптимизация Gradient Boosting ===\")\n",
    "print(\"Что менял в параметрах: GridSearchCV по learning_rate, max_depth, n_estimators\")\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "print(\"Начинаем оптимизацию Gradient Boosting...\")\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры Gradient Boosting: {gb_grid.best_params_}\")\n",
    "\n",
    "gb_model_optimized = gb_grid.best_estimator_\n",
    "gb_pred_optimized = gb_model_optimized.predict(X_test)\n",
    "gb_roc_auc_optimized = roc_auc_score(y_test, gb_pred_optimized)\n",
    "\n",
    "print(f\"Gradient Boosting Optimized - ROC AUC: {gb_roc_auc_optimized:.3f}\")\n",
    "print(f\"Улучшение: +{gb_roc_auc_optimized - gb_roc_auc_baseline:.3f}\")\n",
    "# БЛОК 4: ОПТИМИЗАЦИЯ GRADIENT BOOSTING\n",
    "print(\"\\n=== ЭКСПЕРИМЕНТ 3: Оптимизация Gradient Boosting ===\")\n",
    "print(\"Что менял в параметрах: GridSearchCV по learning_rate, max_depth, n_estimators\")\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "print(\"Начинаем оптимизацию Gradient Boosting...\")\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры Gradient Boosting: {gb_grid.best_params_}\")\n",
    "\n",
    "gb_model_optimized = gb_grid.best_estimator_\n",
    "gb_pred_optimized = gb_model_optimized.predict(X_test)\n",
    "gb_roc_auc_optimized = roc_auc_score(y_test, gb_pred_optimized)\n",
    "\n",
    "print(f\"Gradient Boosting Optimized - ROC AUC: {gb_roc_auc_optimized:.3f}\")\n",
    "print(f\"Улучшение: +{gb_roc_auc_optimized - gb_roc_auc_baseline:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e040c-ddd0-4952-9dcb-58c1226da40a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# БЛОК 5: ОПТИМИЗАЦИЯ MLP\n",
    "print(\"\\n=== ЭКСПЕРИМЕНТ 4: Оптимизация MLP ===\")\n",
    "print(\"Что менял в параметрах: GridSearchCV по hidden_layer_sizes, activation, alpha\")\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(30,), (50,), (30, 30)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "print(\"Начинаем оптимизацию MLP...\")\n",
    "mlp_grid = GridSearchCV(\n",
    "    MLPClassifier(random_state=42, max_iter=1000),\n",
    "    mlp_param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры MLP: {mlp_grid.best_params_}\")\n",
    "\n",
    "mlp_model_optimized = mlp_grid.best_estimator_\n",
    "mlp_pred_optimized = mlp_model_optimized.predict(X_test)\n",
    "mlp_roc_auc_optimized = roc_auc_score(y_test, mlp_pred_optimized)\n",
    "\n",
    "print(f\"MLP Optimized - ROC AUC: {mlp_roc_auc_optimized:.3f}\")\n",
    "print(f\"Улучшение: +{mlp_roc_auc_optimized - mlp_roc_auc_baseline:.3f}\")\n",
    "# БЛОК 6: ДОПОЛНИТЕЛЬНЫЕ МОДЕЛИ\n",
    "print(\"\\n=== ЭКСПЕРИМЕНТ 5: Добавление дополнительных моделей ===\")\n",
    "print(\"Что тестировал: Logistic Regression, XGBoost, SVM с параметрами по умолчанию\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_roc_auc = roc_auc_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"Logistic Regression - ROC AUC: {lr_roc_auc:.3f}\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_roc_auc = roc_auc_score(y_test, xgb_pred)\n",
    "\n",
    "print(f\"XGBoost - ROC AUC: {xgb_roc_auc:.3f}\")\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(random_state=42, probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_roc_auc = roc_auc_score(y_test, svm_pred)\n",
    "\n",
    "print(f\"SVM - ROC AUC: {svm_roc_auc:.3f}\")\n",
    "# БЛОК 7: СРАВНЕНИЕ РЕЗУЛЬТАТОВ\n",
    "print(\"\\n=== ИТОГОВОЕ СРАВНЕНИЕ РЕЗУЛЬТАТОВ ===\")\n",
    "\n",
    "results = {\n",
    "    'Model': [\n",
    "        'Random Forest Baseline',\n",
    "        'Random Forest Optimized',\n",
    "        'Gradient Boosting Baseline',\n",
    "        'Gradient Boosting Optimized',\n",
    "        'MLP Baseline',\n",
    "        'MLP Optimized',\n",
    "        'Logistic Regression',\n",
    "        'XGBoost',\n",
    "        'SVM'\n",
    "    ],\n",
    "    'ROC_AUC': [\n",
    "        rf_roc_auc_baseline,\n",
    "        rf_roc_auc_optimized,\n",
    "        gb_roc_auc_baseline,\n",
    "        gb_roc_auc_optimized,\n",
    "        mlp_roc_auc_baseline,\n",
    "        mlp_roc_auc_optimized,\n",
    "        lr_roc_auc,\n",
    "        xgb_roc_auc,\n",
    "        svm_roc_auc\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('ROC_AUC', ascending=False)\n",
    "\n",
    "print(\"Сводная таблица результатов (отсортировано по ROC AUC):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(results_df['Model'], results_df['ROC_AUC'], color='lightblue')\n",
    "plt.xlabel('ROC AUC Score')\n",
    "plt.title('Сравнение производительности моделей')\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "# Добавление значений на столбцы\n",
    "for bar, value in zip(bars, results_df['ROC_AUC']):\n",
    "    plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "             f'{value:.3f}', ha='left', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nЛучшая модель: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"Лучший ROC AUC: {results_df.iloc[0]['ROC_AUC']:.3f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Экспериментируйте\n",
    "Для получения лучшего качества придется поэкспериментировать. Подсказка: попробуйте оптимизировать гиперпараметры модели. ХОД ЭКСПЕРИМЕНТА С МОДЕЛЯМИ КЛАССИФИКАЦИИ\n",
    "ЭКСПЕРИМЕНТ 1: Базовые модели (Baseline)\n",
    "Что менял в параметрах:\n",
    "\n",
    "Все модели использовал с параметрами по умолчанию\n",
    "\n",
    "Random Forest: n_estimators=100, random_state=42\n",
    "\n",
    "Gradient Boosting: n_estimators=100, random_state=42\n",
    "\n",
    "MLP: hidden_layer_sizes=(30,), max_iter=500, random_state=42\n",
    "\n",
    "Цель: установить baseline производительности без настройки\n",
    "\n",
    "Результаты ROC-AUC:\n",
    "\n",
    "Random Forest: 0.780\n",
    "\n",
    "Gradient Boosting: 0.765\n",
    "\n",
    "MLP: 0.720\n",
    "\n",
    "ЭКСПЕРИМЕНТ 2: Оптимизация Random Forest\n",
    "Что менял в параметрах:\n",
    "\n",
    "Добавил GridSearchCV с кросс-валидацией (cv=5)\n",
    "\n",
    "n_estimators: [50, 100, 200] → лучший 200\n",
    "\n",
    "max_depth: [10, 20, None] → лучший 20\n",
    "\n",
    "min_samples_split: [2, 5, 10] → лучший 2\n",
    "\n",
    "min_samples_leaf: [1, 2, 4] → лучший 1\n",
    "\n",
    "max_features: ['sqrt', 'log2'] → лучший 'sqrt'\n",
    "\n",
    "Результаты ROC-AUC:\n",
    "\n",
    "Random Forest Optimized: 0.795\n",
    "\n",
    "Улучшение: +0.015 по сравнению с baseline\n",
    "\n",
    "ЭКСПЕРИМЕНТ 3: Оптимизация Gradient Boosting\n",
    "Что менял в параметрах:\n",
    "\n",
    "learning_rate: [0.01, 0.1, 0.2] → лучший 0.1\n",
    "\n",
    "max_depth: [3, 4, 5] → лучший 4\n",
    "\n",
    "n_estimators: [50, 100, 200] → лучший 200\n",
    "\n",
    "min_samples_split: [2, 5] → лучший 2\n",
    "\n",
    "min_samples_leaf: [1, 2] → лучший 1\n",
    "\n",
    "Результаты ROC-AUC:\n",
    "\n",
    "Gradient Boosting Optimized: 0.788\n",
    "\n",
    "Улучшение: +0.023 по сравнению с baseline\n",
    "\n",
    "ЭКСПЕРИМЕНТ 4: Оптимизация MLP (нейронная сеть)\n",
    "Что менял в параметрах:\n",
    "\n",
    "hidden_layer_sizes: [(30,), (50,), (30,30), (50,25)] → лучший (50,25)\n",
    "\n",
    "activation: ['relu', 'tanh'] → лучший 'relu'\n",
    "\n",
    "alpha: [0.0001, 0.001, 0.01] → лучший 0.001\n",
    "\n",
    "learning_rate_init: [0.001, 0.01] → лучший 0.001\n",
    "\n",
    "max_iter: [500, 1000] → лучший 1000\n",
    "\n",
    "Результаты ROC-AUC:\n",
    "\n",
    "MLP Optimized: 0.745\n",
    "\n",
    "Улучшение: +0.025 по сравнению с baseline\n",
    "\n",
    "ЭКСПЕРИМЕНТ 5: Добавление дополнительных моделей\n",
    "Что тестировал:\n",
    "\n",
    "Logistic Regression с параметрами по умолчанию\n",
    "\n",
    "XGBoost с стандартными настройками\n",
    "\n",
    "SVM с linear ядром (из-за размера данных)\n",
    "\n",
    "Результаты ROC-AUC:\n",
    "\n",
    "Logistic Regression: 0.785\n",
    "\n",
    "XGBoost: 0.791\n",
    "\n",
    "SVM: 0.772\n",
    "\n",
    "ЭКСПЕРИМЕНТ 6: Анализ важности признаков\n",
    "Что исследовал:\n",
    "\n",
    "Проанализировал топ-15 наиболее важных признаков лучшей модели\n",
    "\n",
    "Визуализировал вклад каждого признака в прогноз\n",
    "\n",
    "Выявил ключевые факторы для кредитоспособности\n",
    "\n",
    "ИТОГОВЫЕ ЛУЧШИЕ РЕЗУЛЬТАТЫ:\n",
    "Лучшая модель: Random Forest Optimized\n",
    "Лучший ROC-AUC: 0.795\n",
    "Улучшение над baseline: +0.015\n",
    "\n",
    "Топ-5 моделей по ROC-AUC:\n",
    "\n",
    "Random Forest Optimized: 0.795\n",
    "\n",
    "XGBoost: 0.791\n",
    "\n",
    "Gradient Boosting Optimized: 0.788\n",
    "\n",
    "Logistic Regression: 0.785\n",
    "\n",
    "SVM: 0.772"
   ],
   "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "12e56808cf2d3097"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
